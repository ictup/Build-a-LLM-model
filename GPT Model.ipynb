{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33ebf1a",
   "metadata": {},
   "source": [
    "## 4.1 实现 LLM 的架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4515cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 100277,    # Vocabulary size (from BPE tokenizer)\n",
    "    \"context_length\": 1024, # Context length( how many token can model handle)\n",
    "    \"emb_dim\": 768,         # Embedding dimension (each token transfer to 768 dims)\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers(how many transofmrer layer do we need)\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d58c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 4.1 A placeholder GPT model architecture class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])      #A\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])                       #B\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):                                       #C\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):                                                     #D\n",
    "        return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):                                              #E\n",
    "    def __init__(self, normalized_shape, eps=1e-5):                           #F\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "#A 为 TransformerBlock 设置占位符\n",
    "#B 为 LayerNorm 设置占位符\n",
    "#C 一个简单的占位类，后续将被真正的 TransformerBlock 替换\n",
    "#D 该模块无实际操作，仅原样返回输入\n",
    "#E 一个简单的占位类，后续将被真正的 DummyLayerNorm 替换\n",
    "#F 此处的参数仅用于模拟LayerNorm接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e9b61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100277"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ed1fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8597,   347, 80202],\n",
       "        [  308,  7141,  3524]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = []\n",
    "\n",
    "txt1 = \"heelodasd\"\n",
    "txt2 = \" nihao\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch,dim=0)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885c9f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.7294, -0.9918, -0.5595,  ..., -0.4872,  0.2833,  0.1160],\n",
       "          [ 0.4177,  1.9711, -0.3894,  ...,  1.3055,  1.0193,  0.0973],\n",
       "          [-0.9279, -0.1050, -0.3882,  ..., -1.4838,  0.0462,  0.1469]],\n",
       " \n",
       "         [[-0.0077, -1.1776, -0.3267,  ..., -0.2297, -0.1586,  1.2162],\n",
       "          [ 0.4273,  1.4703,  1.4208,  ...,  0.3123, -0.6263, -0.3699],\n",
       "          [-1.5987, -0.7349,  0.4377,  ..., -1.4158,  1.7225,  1.9415]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " torch.Size([2, 3, 100277]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "logits,logits.shape\n",
    "# 每个token被转换成了vocab size的维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daea97e",
   "metadata": {},
   "source": [
    "## 4.2 使用层归一化对激活值进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d90e36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
       "         [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
       "        grad_fn=<ReluBackward0>),\n",
       " torch.Size([2, 6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2,5)\n",
    "layer = nn.Sequential(nn.Linear(5,6),nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "out,out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba7437e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1324],\n",
       "         [0.2170]], grad_fn=<MeanBackward1>),\n",
       " torch.Size([2, 1]),\n",
       " tensor([[0.0231],\n",
       "         [0.0398]], grad_fn=<VarBackward0>),\n",
       " torch.Size([2, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = out.mean(dim=-1,keepdim=True)\n",
    "var = out.var(dim=-1,keepdim=True)\n",
    "mean,mean.shape,var,var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603a77c",
   "metadata": {},
   "source": [
    "在计算均值或方差等操作时使用 keepdim=True 参数，可以确保输出张量的维度与输入张量相同，即使该操作通过dim参数减少了张量的维度。例如，如果不使用 keepdim=True，返回的均值张量将是一个二维向量 [0.1324, 0.2170]，而使用 keepdim=True 后，返回的张量则会是一个 2×1 的矩阵 [[0.1324], [0.2170]]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0312d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [5.9605e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7e830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "# 关闭科学计数法\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f804eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1,keepdim=True,unbiased=False)\n",
    "        mean_x = (x-mean) / torch.sqrt(var + self.eps)\n",
    "        y = self.scale * mean_x + self.shift\n",
    "        return y\n",
    "# 变量 eps 是一个小常数（epsilon），在归一化过程中加到方差上，\n",
    "# 以防止出现除零错误。scale 和 shift 是两个可训练参数（与输入具有相同的维度）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e61dd8",
   "metadata": {},
   "source": [
    "`unbiased=False` 是 `torch.var` 函数的一个参数，控制方差的计算方式：\n",
    "* **当 `unbiased=True`（默认）**，方差是无偏估计，会除以 $N-1$（样本数减1）。\n",
    "* **当 `unbiased=False`**，方差是有偏估计，会除以 $N$（样本数）。\n",
    "* **无偏（unbiased=True）**:\n",
    "  $\\text{Var} = \\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\bar{x})^2$\n",
    "* **有偏（unbiased=False）**:\n",
    "  $\\text{Var} = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2$\n",
    "\n",
    "**为什么 LayerNorm 用 unbiased=False？**\n",
    "LayerNorm 是对每个样本自己的特征做归一化（不是整批），用有偏估计（除以N）与标准实现一致，数值更稳定，也和 numpy 的 `var` 行为一致（默认除以N）。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da71ef47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af7d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d5f51",
   "metadata": {},
   "source": [
    "## 4.3 实现带有 GELU 激活函数的前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "864d42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 4.3 An implementation of the GELU activation function\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186d7054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)                                          #A\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#A 在 -3 到 3 的范围内生成 100 个样本数据点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901fd58",
   "metadata": {},
   "source": [
    "ReLU 是一个分段线性函数，输入为正时输出输入值本身，否则输出零。而 GELU 是一种平滑的非线性函数，它近似于 ReLU，但在负值上也具有非零梯度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe162ee",
   "metadata": {},
   "source": [
    "GELU 的平滑性使其在训练过程中具有更好的优化特性，能够对模型参数进行更细微的调整。相比之下，ReLU 在零点处有一个拐角，这在网络深度较大或结构复杂时可能会增加优化难度。此外，ReLU 对所有负输入的输出为零，而 GELU 对负值允许一个小的非零输出。这意味着在训练过程中，接收负输入的神经元也能对学习过程产生一定的贡献，尽管贡献程度不及正输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9521f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"])\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7864d82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3731, -0.2161,  0.1972,  ..., -0.2462,  0.0535,  0.2413],\n",
       "          [ 0.0069,  0.0609,  0.3952,  ...,  0.1626, -0.0415, -0.1237],\n",
       "          [ 0.1569, -0.1565, -0.0789,  ..., -0.3007,  0.2389, -0.1702]],\n",
       " \n",
       "         [[ 0.2887,  0.0783,  0.1038,  ..., -0.2605, -0.0504, -0.2268],\n",
       "          [-0.0889,  0.2274,  0.0563,  ..., -0.2062,  0.0148, -0.2420],\n",
       "          [ 0.2520, -0.0005, -0.2848,  ..., -0.0739, -0.0354,  0.0410]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " torch.Size([2, 3, 768]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "x = torch.randn(2,3,768)\n",
    "y = ffn(x)\n",
    "y,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "154a40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self,layer_sizes,use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            # Implement 5 layers\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                # 需要保证维度一致才能使用残差链接\n",
    "                x = layer_output + x\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd9c23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_size = [3,3,3,3,3,1]\n",
    "sample_input = torch.tensor([[1.,0.,-1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layers_size,use_shortcut=False\n",
    ")\n",
    "sample_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d67dc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model,x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = nn.MSELoss()\n",
    "    l = loss(output,target)\n",
    "    l.backward()\n",
    "\n",
    "    for name,param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e5fe79",
   "metadata": {},
   "source": [
    "当调用 loss.backward() 时，PyTorch 会为模型的每一层计算损失的梯度。我们可以通过 model.named_parameters() 遍历权重参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa9ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173590746708214\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152042235247791\n",
      "layers.3.0.weight has gradient mean of 0.0013988739810883999\n",
      "layers.4.0.weight has gradient mean of 0.00504964729771018\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5146ae5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.0014432318275794387\n",
      "layers.1.0.weight has gradient mean of 0.004846962168812752\n",
      "layers.2.0.weight has gradient mean of 0.004138901364058256\n",
      "layers.3.0.weight has gradient mean of 0.005915128160268068\n",
      "layers.4.0.weight has gradient mean of 0.03265950828790665\n"
     ]
    }
   ],
   "source": [
    "model_with_shotcut = ExampleDeepNeuralNetwork(\n",
    "    layers_size,use_shortcut=True\n",
    ")\n",
    "\n",
    "print_gradients(model_with_shotcut,sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41328ef",
   "metadata": {},
   "source": [
    "从输出结果可以看到，最后一层（layers.4）的梯度依然比其他层更大。然而，随着接近第一层（layers.0），梯度值逐渐趋于稳定，并未缩小到几乎消失的程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07896196",
   "metadata": {},
   "source": [
    "能够很好的缓解当神经网络深度很深的时候，梯度消失的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb5b0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: multi_head_attention.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, max_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.queries = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.keys = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.values = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(max_length, max_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, d_in = x.shape\n",
    "        assert num_tokens <= self.mask.shape[0], \"num_tokens exceeds max_length\"\n",
    "\n",
    "        queries = self.queries(x).view(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = self.keys(x).view(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = self.values(x).view(batch_size, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        queries = queries.transpose(1, 2)  # (batch, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(queries, keys.transpose(-2, -1))  # (batch, num_heads, num_tokens, num_tokens)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens].unsqueeze(0).unsqueeze(0)\n",
    "        attn_scores = attn_scores.masked_fill(mask_bool, float('-inf'))\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / (self.head_dim ** 0.5), dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vecs = torch.matmul(attn_weights, values)  # (batch, num_heads, num_tokens, head_dim)\n",
    "        context_vecs = context_vecs.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "        context_vecs = self.proj(context_vecs)\n",
    "        return context_vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3fd9c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3])      # shape: [3]\n",
    "y = x.unsqueeze(0)               # shape: [1, 3]\n",
    "z = x.unsqueeze(1)               # shape: [3, 1]\n",
    "# 因为x是一维的，所以y就是在一维前加一维，变成1，3 \n",
    "# z是在一维后面再加一维，变成3，1\n",
    "print(x.shape)  # torch.Size([3])\n",
    "print(y.shape)  # torch.Size([1, 3])\n",
    "print(z.shape)  # torch.Size([3, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "146992e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,num_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([#需要传入一个列表\n",
    "            nn.Sequential(nn.Linear(num_dim,4*num_dim)),\n",
    "            GELU(),\n",
    "            nn.Sequential(nn.Linear(4*num_dim,num_dim)),\n",
    "        ])\n",
    "\n",
    "    def forward(self,x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,num_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.register_buffer(\"scale\", torch.ones(num_dim))\n",
    "        self.register_buffer(\"shift\", torch.zeros(num_dim))\n",
    "\n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim=-1,keepdim=True)\n",
    "        var = x.var(dim=-1,keepdim=True,unbiased = False)\n",
    "        y = (x-mean) - torch.sqrt(var + self.eps)\n",
    "        return self.scale * y + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fea0aa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 100277,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41c081c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg[\"emb_dim\"],\n",
    "            d_out = cfg[\"emb_dim\"],\n",
    "            max_length= cfg[\"context_length\"],\n",
    "            dropout = cfg[\"drop_rate\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg[\"emb_dim\"])\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shotcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self,x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shotcut(x)\n",
    "        x = x + shortcut\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shotcut(x)\n",
    "        x = shortcut + x\n",
    "        return x\n",
    "# 归一化-- multihead attn --dropout -- resnet -- 归一化 -- ff -- dropout -- resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70d3db5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768)                    #A\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "#A 建一个形状为 [batch_size, num_tokens, emb_dim] 的输入张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee110d98",
   "metadata": {},
   "source": [
    "Transformer 模块结构中保持数据形状不变并非偶然，而是其设计的一个关键特性。这种设计使 Transformer 擅长处理各种序列到序列任务，因为每个输出向量直接对应一个输入向量，保持一一对应关系。然而，虽然维度一致，但输出向量是包含整个输入序列信息的“上下文向量”。也就是说，尽管序列的物理维度（长度和特征维度）在经过 Transformer 模块时保持不变，但每个输出向量的内容会被重新编码，融合整个输入序列的上下文信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eb621a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 4.7 The GPT model architecture implementation\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "        # 将每个token的embdim维度嵌入向量再转换成vocabsize大小的向量，然后计算softmax，选出这个token最有可能是什么？ dim=-1\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))      #A\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    " #A 设备设置将根据输入数据所在的位置选择在 CPU 或 GPU 上训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "562870d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[ 8597,   347, 80202],\n",
      "        [  308,  7141,  3524]])\n",
      "\n",
      "Output shape: torch.Size([2, 3, 100277])\n",
      "tensor([[[ 6.9786,  1.9400, 14.0354,  ..., -2.2986,  0.8146, -3.0674],\n",
      "         [ 4.5567,  0.1219,  7.7915,  ...,  2.6425, -1.1140,  3.0169],\n",
      "         [ 1.5988,  3.9577,  9.5935,  ..., -4.4785,  1.3988, -7.7583]],\n",
      "\n",
      "        [[-4.0090,  2.5505,  7.9679,  ..., -2.8691, -6.3033, -6.7236],\n",
      "         [ 3.0305,  8.3174, 12.8744,  ..., -1.6319, -5.9147, -0.8746],\n",
      "         [ 5.3054,  1.5535,  8.3648,  ..., -5.5964, -3.9789,  0.2269]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ff71153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 239,801,856\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a38bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([100277, 768])\n",
      "Output layer shape: torch.Size([100277, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05947fc6",
   "metadata": {},
   "source": [
    "原因在于 GPT-2 架构中使用了一种称为‘权重共享’的概念，这意味着 GPT-2 架构将 token 嵌入层的权重复用于输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04e681f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 162,789,120\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c39f23",
   "metadata": {},
   "source": [
    "权重共享能够减少模型的整体内存占用和计算复杂度。然而，根据我的经验，分别使用独立的 token 嵌入层和输出层会使训练效果和模型性能更佳，因此在我们的 GPT 模型实现中，我们使用了独立的嵌入层和输出层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a753464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 914.77 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4                 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024)    #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")\n",
    "\n",
    "#A 计算参数总大小（假设每个参数为 float32 类型，占用 4 字节）\n",
    "#B 转换为 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d034e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 4.8 A function for the GPT model to generate text\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size): #A\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]                           #B\n",
    "        with torch.no_grad():\n",
    "           logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]                                   #C\n",
    "        probas = torch.softmax(logits, dim=-1)                      #D\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)       #E\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                     #F\n",
    "\n",
    "    return idx\n",
    "\n",
    "#“贪婪解码（Greedy Decoding）” 是一种在生成文本时，每一步都选择概率最大的那个 token 的策略。\n",
    "#A idx 是当前上下文中索引的数组，形状为 (batch, n_tokens)\n",
    "#B 若上下文长度超出支持范围，则进行裁剪。例如，若模型仅支持 5 个 token，而上下文长度为 10，仅使用最后 5 个 token 作为上下文\n",
    "#C 仅关注最后一个时间步，将形状从 (batch, n_token, vocab_size) 转换为 (batch, vocab_size)\n",
    "#D probas 的形状为 (batch, vocab_size)\n",
    "#E idx_next 的形状为 (batch, 1)\n",
    "#F 将采样的索引追加到当前序列中，此时 idx 的形状为 (batch, n_tokens+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78bcf5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15339, 38868, 1097]\n"
     ]
    }
   ],
   "source": [
    "start_context = \"hello,I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d3c8791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15339, 38868,  1097]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = torch.tensor(encoded).unsqueeze(0)\n",
    "encoded,encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2c5798f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15339, 38868,  1097, 40889, 46616, 40889, 46616, 46616, 46616]])\n",
      "Output length: 9\n"
     ]
    }
   ],
   "source": [
    "model.eval()             #A\n",
    "out = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=encoded,\n",
    "    max_new_tokens=6,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))\n",
    "\n",
    "#A 禁用 dropout，因为当前不是在训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11046ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello,I am(edge defenses(edge defenses defenses defenses'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = tokenizer.decode(out.squeeze(0).tolist())\n",
    "# 因为只输入了一个句子 batchsize=0，所以去掉，\n",
    "# 并且tokenizer只能decode token序列\n",
    "# 如果有多个序列，需要使用batch_decode\n",
    "# 现在是 [1,lenoftoken]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9546b0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello,I am(edge defenses(edge defenses defenses defenses']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded1 = tokenizer.decode_batch(out.tolist())\n",
    "decoded1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4057ac",
   "metadata": {},
   "source": [
    "# 在无标记数据集上进行预训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b2c9e",
   "metadata": {},
   "source": [
    "## 5.1 生成式文本模型的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8065b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,        #A\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,             #B\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "\n",
    "#A 我们将上下文长度从1024个token缩短到256个token\n",
    "#B 将 dropout 设置为 0 是一种常见的做法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df1d89f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you horn horn horn horn horn horn continuum horn horn horn\n"
     ]
    }
   ],
   "source": [
    "# Listing 5.1 Utility functions for text to token ID conversion\n",
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded, dtype=torch.long).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b698c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                       [40, 1107, 588]])    # \"I really like\"]\n",
    "# Matching these inputs, the `targets` contain the token IDs we aim for the model to produce:\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]) # \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c1e10a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "               0.0000,     0.0000],\n",
       "          [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "               0.0000,     0.0000],\n",
       "          [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "               0.0000,     0.0000]],\n",
       " \n",
       "         [[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "               0.0000,     0.0000],\n",
       "          [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "               0.0000,     0.0000],\n",
       "          [    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
       "               0.0000,     0.0000]]]),\n",
       " torch.Size([2, 3, 50257]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits,dim=-1)\n",
    "probas,probas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a4f42",
   "metadata": {},
   "source": [
    "第一个数字 2 表示输入中的两个样本（行），即批次大小。第二个数字 3 表示每个样本包含的 token 数量。最后一个数字表示嵌入维度的大小，通常由词汇表大小决定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da341325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[23545],\n",
      "         [12718],\n",
      "         [12718]],\n",
      "\n",
      "        [[12718],\n",
      "         [26733],\n",
      "         [ 4929]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "token_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22541318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: herence horn horn\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "#When we decode these tokens, we find that these output tokens are quite different from the target tokens we want the model to generate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8681330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1282d056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3626,  6100,   345],\n",
       "        [ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa27ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([    0.0000,     0.0000,     0.0000])\n",
      "Text 2: tensor([    0.0000,     0.0000,     0.0000])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)\n",
    "# 等价于 ：probas[0, [0, 1, 2], [3626, 6100, 345]]\n",
    "# [\n",
    "#   probas[0, 0, 3626],\n",
    "#   probas[0, 1, 6100],\n",
    "#   probas[0, 2, 345]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "029e4c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-20.6112, -32.4946, -14.5736, -37.0555, -24.4030, -35.7475])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "# cat没有指定维度的时候，默认按照行拼接\n",
    "# 更推荐先log再cat\n",
    "#  如果直接相加 不cat一个新的向量， 不好计算反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086ff96",
   "metadata": {},
   "source": [
    "交叉熵损失一般写为 -log(predict[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1668a3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-20.6112, -32.4946, -14.5736])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(target_probas_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "770a0499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-20.6112, -32.4946, -14.5736, -37.0555, -24.4030, -35.7475])\n"
     ]
    }
   ],
   "source": [
    "log_probas1 = torch.cat((torch.log(target_probas_1), torch.log(target_probas_2)))\n",
    "print(log_probas1)\n",
    "# 这个方法不能拓展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "748336ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-27.4809)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14cc3c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)\n",
    "# The resulting shapes are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b734169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ce35fb",
   "metadata": {},
   "source": [
    "在 PyTorch 中使用交叉熵损失函数时，我们需要将这些张量展平，以便在批量维度上进行合并：\n",
    "请记住，targets 是希望 LLM 生成的目标 token ID，而 logits 包含了在进入 softmax 函数之前的模型原始输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43c280e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27.4809)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "802e6207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20479, 5145)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path,\"r\",encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()# 将整个文件当作整体来处理\n",
    "    # readlines（）将文件每一行当成独立字符串进行处理，全部组成一个列表，当文件很大的时候，可能会导致内存不足\n",
    "len(text_data),len(tokenizer.encode(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f022c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6fe3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "test_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38233586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tiktoken\n",
    "\n",
    "class GPTdataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input = []\n",
    "        self.predict = []\n",
    "\n",
    "        # 编码整个文本为token id序列\n",
    "        text_ids = tokenizer.encode(text)\n",
    "        # tokenizer 返回的是list而不是tensor，需要使用torch.tensor来进行转化。\n",
    "        # 按照max_length窗口、stride滑动窗口分块\n",
    "        for i in range(0, len(text_ids) - max_length, stride):\n",
    "            input_ids = text_ids[i : i + max_length]\n",
    "            label_ids = text_ids[i + 1 : i + 1 + max_length]\n",
    "\n",
    "            self.input.append(torch.tensor(input_ids, dtype=torch.long))\n",
    "            self.predict.append(torch.tensor(label_ids, dtype=torch.long))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input[index], self.predict[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "def create_dataloader_v1(input_text, batch_size=2, max_length=256, stride=256, drop_last=True, shuffle=True, num_workers=0):\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-2\")\n",
    "    dataset = GPTdataset(input_text, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "# 假设train_data, test_data, GPT_CONFIG_124M都定义了\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=4,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    test_data,\n",
    "    batch_size=4,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "715c111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([4, 256]) torch.Size([4, 256])\n",
      "torch.Size([4, 256]) torch.Size([4, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcbbf5",
   "metadata": {},
   "source": [
    "注意！ to(device)会复制一份到device，而不是就地修改；如果数据量巨大，建议按需处理。x = x.to(device) 就会抛弃掉原有的数据，创建新的内存，这样变量 x 就指向了新 device 上的 tensor，原来的旧 tensor（如果没有别的引用）会被垃圾回收。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f789c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)       #A\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )# logits.shape [batchsize,numtoken,vocabsize]\n",
    "    # target/input shape ]batchsize,numtoken\n",
    "    # 合并之后 [batchsize*numtoken,]and [batchsize*numtoken,vocabsize]\n",
    "    return loss\n",
    "\n",
    "#A 将数据传输到指定设备（如 GPU），使数据能够在 GPU 上处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf86289",
   "metadata": {},
   "source": [
    "flatten()\n",
    "总是返回拷贝/新tensor，默认会跨所有维度，可以选定某两维展平（如flatten(0, 1)）。\n",
    "\n",
    "支持指定起止维度展开，是最通用且安全的方法。\n",
    "\n",
    "flatten() 不会出错，即使张量不连续。\n",
    "\n",
    "view(-1)\n",
    "必须保证张量是内存连续的，否则会报错（比如某些转置、切片操作后）。\n",
    "\n",
    "通常更快，因为不做数据拷贝，只是更改视图。\n",
    "\n",
    "需要时可以配合 .contiguous()。\n",
    "\n",
    "reshape(-1)\n",
    "更智能，优先尝试返回view（快），但如果不能则自动拷贝数据。\n",
    "\n",
    "用 reshape 一般不会报“contiguous”错，兼容性最好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49f8d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.2 Function to compute the training and validation loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)                                    #A\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))                  #B\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()                                     #C\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches                                       #D\n",
    "\n",
    "\n",
    "#A 如果没有指定批次数，将自动遍历所有批次\n",
    "#B 若批次数超过数据加载器的总批次数，则减少批次数使其与数据加载器的批次数相匹配\n",
    "#C 每个批次的损失求和\n",
    "#D 对所有批次的损失取平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bbaabb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 24.42553424835205\n",
      "Validation loss: 24.09621810913086\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #A\n",
    "model.to(device)\n",
    "with torch.no_grad():                                                 #B\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)        #C\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "\n",
    "\n",
    "#A 如果你的设备配备了支持 CUDA 的 GPU，LLM 将自动在 GPU 上进行训练，无需更改代码\n",
    "#B 因为当前不在训练，为提高效率，关闭梯度跟踪\n",
    "#C 通过 device 设置确保数据与 LLM 模型加载到同一设备上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169076f",
   "metadata": {},
   "source": [
    "在这里出现了个问题，直接使用torch.tensor（）不能直接跟随to（device），如果要写能够跟随模型一起转移的变量，需要用 nn.Parameters / register_buffer 前者是需要被更新的，后者是不需要更新的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac470ec",
   "metadata": {},
   "source": [
    "## 5.2 训练 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0dbbea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(256, 768)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0725b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()                #A\n",
    "    with torch.no_grad():       #B\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "#A 评估阶段禁用 dropout，以确保结果稳定、可复现\n",
    "#B 禁用梯度跟踪，减少计算开销"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2af9a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \")) # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49196e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.3 The main function for pretraining LLMs\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []                        #A\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):                                                 #B\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()                                                   #C\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()                                                         #D\n",
    "            optimizer.step()                                                        #E\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:                                        #F\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(                                                  #G\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "#A 初始化用于记录损失和已处理 token 数量的列表\n",
    "#B 开始主训练循环\n",
    "#C 重置上一批次的损失梯度\n",
    "#D 计算损失梯度\n",
    "#E 使用损失梯度更新模型权重\n",
    "#F 可选的评估步骤\n",
    "#G 每个 epoch 结束后打印示例文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9329a0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"gpt-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62c4f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 19.870, Val loss 19.592\n",
      "Every effort moves you,hs Vide Minnesota Minnesota Minnesota Minnesotaanova exquisiteす heavyanova prescriptions Pay Minnesota Minnesota Minnesota Minnesotaanovaす1968ixed,,,,hsNine Minnesota Minnesota Various Minnesota Minnesotaanova widespreadNinelarglargENN Various wherequs widespread Minnesota Minnesota del Various where, Minnesota\n",
      "Ep 2 (Step 000005): Train loss 12.498, Val loss 12.579\n",
      "Every effort moves you, GohanOWN charred 820 dentist widespreadbe,,, GohanOWN charred Thrvest charred mines schema endogenous widespreadalf,,,, ScenesconstOWN prescriptions Minimum schema mines schemaARGET Thr Scenes viewing incitingOWN tackling schema flight,,,)—)—)—ANK\n",
      "Ep 3 (Step 000010): Train loss 11.317, Val loss 11.479\n",
      "Every effort moves you, GohanYes University unsigned dentist forecasting you, Gohan penal Gohan forecasting Short viewing World Productionsolesterolalf,, Gohan Gohan nan vaccination the tail PastRecipe noticing)—astic transformed much schema mills sing viewing inciting UniversityRef REST Blade,)—asticac,)—)—\n",
      "Ep 4 (Step 000015): Train loss 10.871, Val loss 10.965\n",
      "Every effort moves you, GohanYes REDRef, Gohanaign408,, Gohan TED..408 SDK JR, civilization, Gohan Gohan.        attainment, Blade Gohan civilization .. asticedomRefRef attainment,)—)—)—.\n",
      "Every effort moves you, GohanYes RED Pay atomic the,,,,, TED. TED, UAE,,,, Gohan Gohan RED,,,--, civilization--,,, Gohan gobl,,,,,,,,,,,,, Gohan\n",
      "Ep 6 (Step 000020): Train loss 10.303, Val loss 10.595\n",
      "Every effort moves you, GohanYes RED GohanYes the,,,,, Stur mL openly Gohan naturally,,,, Gohan Gohan Minimum,,-- TED, civilization--,,, Gohan gobl,,,,, bureaucrats suggestion,,,,,,--\n",
      "Ep 7 (Step 000025): Train loss 10.055, Val loss 10.343\n",
      "Every effort moves you, GohanYes RED GohanYes the--,,--, Stur,--, naturally,, civilization, Gohan Gohan toys the the -- of a    bureaucrats,,,-- I,, bureaucrats,,,,,,,--\n",
      "Ep 8 (Step 000030): Train loss 9.691, Val loss 10.114\n",
      "Every effort moves you, GohanYes--,, Gohan--,,,,--,--,,,,,, Gohan Gohan--,,----,--,,,,,,,--,,, bureaucrats,,,,,,,--\n",
      "Ep 9 (Step 000035): Train loss 9.553, Val loss 9.922\n",
      "Every effort moves you, GohanYes--,, Gohan--,,,,,,--,,,,,, Gohan Gohan--,,----,--,,,, Gohan--,-- I,, bureaucrats,,,,,,,--\n",
      "Every effort moves you, GohanYes--,, Gohan--,,,, I,--,,,,,, Gohan Gohan--,,----,--,,,, Gohan--,-- I,, bureaucrats,,,,,,,--\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.01)      #A\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#A .parameters() 方法返回模型的所有可训练权重参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62d38221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny() #A\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0) #B\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "#A 创建与 y 轴共用的第二个 x 轴\n",
    "#B 用于对齐刻度的隐藏图形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "089850f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_emb.weight: torch.Size([50257, 768])\n",
      "pos_emb.weight: torch.Size([256, 768])\n",
      "trf_blocks.0.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.0.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.0.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.0.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.0.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.0.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.0.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.0.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.0.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.1.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.1.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.1.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.1.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.1.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.1.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.1.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.1.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.1.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.2.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.2.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.2.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.2.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.2.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.2.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.2.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.2.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.2.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.3.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.3.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.3.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.3.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.3.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.3.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.3.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.3.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.3.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.4.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.4.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.4.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.4.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.4.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.4.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.4.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.4.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.4.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.5.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.5.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.5.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.5.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.5.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.5.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.5.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.5.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.5.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.6.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.6.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.6.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.6.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.6.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.6.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.6.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.6.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.6.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.7.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.7.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.7.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.7.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.7.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.7.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.7.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.7.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.7.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.8.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.8.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.8.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.8.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.8.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.8.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.8.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.8.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.8.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.9.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.9.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.9.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.9.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.9.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.9.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.9.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.9.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.9.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.10.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.10.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.10.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.10.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.10.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.10.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.10.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.10.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.10.ff.layers.2.0.bias: torch.Size([768])\n",
      "trf_blocks.11.att.queries.weight: torch.Size([768, 768])\n",
      "trf_blocks.11.att.keys.weight: torch.Size([768, 768])\n",
      "trf_blocks.11.att.values.weight: torch.Size([768, 768])\n",
      "trf_blocks.11.att.proj.weight: torch.Size([768, 768])\n",
      "trf_blocks.11.att.proj.bias: torch.Size([768])\n",
      "trf_blocks.11.ff.layers.0.0.weight: torch.Size([3072, 768])\n",
      "trf_blocks.11.ff.layers.0.0.bias: torch.Size([3072])\n",
      "trf_blocks.11.ff.layers.2.0.weight: torch.Size([768, 3072])\n",
      "trf_blocks.11.ff.layers.2.0.bias: torch.Size([768])\n",
      "out_head.weight: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2f71c",
   "metadata": {},
   "source": [
    "## 5.3 通过解码策略控制生成结果的随机性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b779af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you, GohanYes--,, Gohan--,,,, I,--,,,,,, Gohan Gohan--,\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c42c13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "# argmax 返回最大值位置的張量\n",
    "# .item() 用于把只包含一个数值的张量（tensor）转换为普通的 Python 数值类型\n",
    "# （比如 int 或 float）。\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "635a7769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f243f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510a8fe",
   "metadata": {},
   "source": [
    "采样只能选取大于0的数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6ca58",
   "metadata": {},
   "source": [
    "torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None)\n",
    "\n",
    "input: 一维/二维 tensor，每个元素是权重（可不是概率，但都应≥0，不能全为0）。\n",
    "\n",
    "num_samples: 采样个数。\n",
    "\n",
    "replacement: 是否有放回采样（默认False）。True时每次都可被选，False时每次选中后不能再次被选。\n",
    "\n",
    "返回值：shape为 [num_samples] 的 LongTensor，元素是下标。\n",
    "\n",
    "import torch\n",
    "weights = torch.tensor([0.1, 0.2, 0.7])\n",
    "samples = torch.multinomial(weights, 5, replacement=True)\n",
    "print(samples)\n",
    "结果可能是：tensor([2, 1, 2, 2, 0])\n",
    "\n",
    "2 被选中的概率最大（0.7），所以很可能多次被选中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e334d8",
   "metadata": {},
   "source": [
    "\n",
    "torch.bincount(arr)：统计一维整数 tensor 每个可能取值的出现次数（频率）。\n",
    "\n",
    "输入如 [2, 1, 2, 2, 0, 1]\n",
    "\n",
    "返回 [1, 2, 3]\n",
    "\n",
    "0出现1次，1出现2次，2出现3次。\n",
    "\n",
    "和 numpy.bincount 类似，是高效计数统计工具（只能用于非负整数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e570e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  7.0587,  -3.2935, -13.1793,  ...,   2.9044,   3.7385,   8.4152],\n",
       "          [  4.0956,  -5.2586, -13.6300,  ...,   2.8654,   3.5133,   8.8506],\n",
       "          [  5.3851,  -6.1039, -11.4961,  ...,   3.3582,   5.0339,   7.4872]],\n",
       " \n",
       "         [[  3.5163,  -0.4896, -11.9791,  ...,  -0.7037,   6.5363,   9.6311],\n",
       "          [  5.1303,  -0.9495, -12.8363,  ...,   1.1346,   6.3823,   8.0247],\n",
       "          [  6.9907,  -0.9637,  -9.4921,  ...,  -0.7716,   7.9530,   7.7548]]]),\n",
       " torch.Size([2, 3, 50257]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits,logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d271ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "#Temperatures greater than 1 result in more uniformly distributed token probabilities, and Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions. Let's illustrate this by plotting the original probabilities alongside probabilities scaled with different temperature values:\n",
    "temperatures = [1, 0.1, 5]             #A\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "                   bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#A 原始、较低和较高置信度\n",
    "\n",
    "# 其中 temperature 默认为 1。\n",
    "# temperature < 1：分母变小，softmax 更“激进”，\n",
    "# 概率分布更加尖锐，最大概率的 token 更容易被选中（更“自信”）。\n",
    "# temperature > 1：分母变大，softmax 更“温和”，\n",
    "# 概率分布更平缓，各 token 被采样的概率差距缩小，生成内容更加多样、更加“随机”。\n",
    "## 较高的 temperature 值会使下一词的概率分布更均匀，\n",
    "# 从而降低模型反复选择最可能词的概率，这样可以生成更多样化的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998204b",
   "metadata": {},
   "source": [
    "在 top-k 采样中，我们可以将采样限制在最有可能的前 k 个 token 内，并通过将其他 token 的概率设为零，将它们排除在选择之外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "544f1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "991733bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],   #A\n",
    "    input=torch.tensor(float('-inf'),device = next_token_logits.device),              #B\n",
    "    other=next_token_logits                         #C\n",
    ")# 如果A成立，那么就是input，否则就是other\n",
    "print(new_logits)\n",
    "\n",
    "#A 识别出小于 top 3 最小值的 logits\n",
    "#B 将这些较小的 logits 赋值为负无穷大\n",
    "#C 保留所有其他 token 的原始 logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d1b091a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits,dim=0)\n",
    "topk_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9966d6b",
   "metadata": {},
   "source": [
    "### 5.3.3 对文本生成函数进行调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fcabd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.4 A modified text generation function with more diversity\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):                             #A\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:                                   #B\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "\n",
    "        if temperature > 0.0:                                       #C\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:                                                       #D\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:                                      #E\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n",
    "\n",
    "\n",
    "#A For循环与之前相同：获取logits，仅关注最后的时间步\n",
    "#B 在新步骤中，通过top-k采样过滤logits\n",
    "#C 在新步骤中应用temperature scaling\n",
    "#D 在未使用temperature scaling时，执行贪婪的下一个token选择\n",
    "#E 如果遇到序列结束token且指定了eos_id，则提前停止生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e1495a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you, the a browserACK, a Iretchedestonesra, Gohan Gohan.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb9ff16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "870668b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "#dropout 通过在训练过程中随机“丢弃”某些神经元，以防止模型过拟合。\n",
    "# 然而，在推理阶段，我们不希望随机丢弃网络中学到的任何信息。\n",
    "# 通过使用 model.eval()，模型会切换到推理阶段的评估模式，从而禁用 dropout 层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48716fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3419864a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7320bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x20548a71450>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1bb9f2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 77.0kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.33MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 90.0kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:05<00:00, 3.98MiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 2.07MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 737kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 702kiB/s] \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2 \n",
    "settings, params = download_and_load_gpt2( model_size=\"124M\", models_dir=\"gpt2\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91928c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe45a0d",
   "metadata": {},
   "source": [
    "2. Parameter dictionary keys（模型权重参数dict中的主键）\n",
    "'blocks'：Transformer主干的每一层（block）的参数集合。\n",
    "GPT-2 结构是 N 层 transformer block 堆叠，blocks 保存了每层的注意力、MLP等权重。\n",
    "\n",
    "'b'、'g'（有些实现用 'ln_f'）：最终LayerNorm（归一化层）的参数\n",
    "\n",
    "'b' 可能指 layer norm 的 bias（偏置）\n",
    "\n",
    "'g' 可能指 layer norm 的 gain（缩放/scale）\n",
    "\n",
    "这两项常用于最后一层输出归一化（final layernorm）\n",
    "\n",
    "'wpe'：位置编码参数（word positional embedding）\n",
    "\n",
    "shape=[n_ctx, n_embd]\n",
    "\n",
    "每个位置一个向量，用于捕获 token 的序列顺序信息\n",
    "\n",
    "'wte'：词嵌入参数（word token embedding）\n",
    "\n",
    "shape=[n_vocab, n_embd]\n",
    "\n",
    "每个 token id 对应一个 embedding 向量，是输入 token id → 向量的“字典”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c5cacebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54eb0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 256, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': False}\n"
     ]
    }
   ],
   "source": [
    "# First, we create a dictionary that lists the differences between the different GPT model sizes, as explained in Figure 5.17:\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "# Suppose we are interested in loading the smallest model, \"gpt2-small (124M)\". We can use the corresponding settings from the model_configs table able to update our full-length GPT_CONFIG_124M we defined and used earlier throughout the chapter as follows:\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "print(NEW_CONFIG)\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "# 如果 key 已存在，用新值覆盖/替换原有值。\n",
    "# 如果 key 不存在，就把新 key/value 直接加进来。\n",
    "# 不影响原来的 dict，只在拷贝后的 NEW_CONFIG 上生效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ca8f58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "19d2ddae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (queries): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (keys): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (values): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shotcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "# We can now use the updated NEW_CONFIG dictionary to initialize a new GPTModel instance:\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11065dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b73a8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.5 Loading OpenAI weights into our GPT model code\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])               #A\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    for b in range(len(params[\"blocks\"])):                                       #B\n",
    "        q_w, k_w, v_w = np.split(                                                #C\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])                   #D\n",
    "\n",
    "\n",
    "#A 将模型的位置嵌入和token 嵌入的权重设置为 params 中指定的值\n",
    "#B 遍历模型中的每个 Transformer 模块\n",
    "#C 使用 np.split 函数将注意力和偏置权重分为三等份，分别用于查询、键和值组件\n",
    "#D OpenAI 的原始 GPT-2 模型在输出层中复用了 token 嵌入的权重，以减少参数总量，这一概念称为权重共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fb7b8daa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiHeadAttention' object has no attribute 'W_query'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mload_weights_into_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m gpt\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[99], line 11\u001b[0m, in \u001b[0;36mload_weights_into_gpt\u001b[1;34m(gpt, params)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m])):                                       \u001b[38;5;66;03m#B\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     q_w, k_w, v_w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(                                                \u001b[38;5;66;03m#C\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         (params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks\u001b[39m\u001b[38;5;124m\"\u001b[39m][b][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc_attn\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m     gpt\u001b[38;5;241m.\u001b[39mtrf_blocks[b]\u001b[38;5;241m.\u001b[39matt\u001b[38;5;241m.\u001b[39mW_query\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m assign(\n\u001b[1;32m---> 11\u001b[0m         \u001b[43mgpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrf_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_query\u001b[49m\u001b[38;5;241m.\u001b[39mweight, q_w\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     12\u001b[0m     gpt\u001b[38;5;241m.\u001b[39mtrf_blocks[b]\u001b[38;5;241m.\u001b[39matt\u001b[38;5;241m.\u001b[39mW_key\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m assign(\n\u001b[0;32m     13\u001b[0m         gpt\u001b[38;5;241m.\u001b[39mtrf_blocks[b]\u001b[38;5;241m.\u001b[39matt\u001b[38;5;241m.\u001b[39mW_key\u001b[38;5;241m.\u001b[39mweight, k_w\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     14\u001b[0m     gpt\u001b[38;5;241m.\u001b[39mtrf_blocks[b]\u001b[38;5;241m.\u001b[39matt\u001b[38;5;241m.\u001b[39mW_value\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m assign(\n\u001b[0;32m     15\u001b[0m         gpt\u001b[38;5;241m.\u001b[39mtrf_blocks[b]\u001b[38;5;241m.\u001b[39matt\u001b[38;5;241m.\u001b[39mW_value\u001b[38;5;241m.\u001b[39mweight, v_w\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32md:\\python\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultiHeadAttention' object has no attribute 'W_query'"
     ]
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
